# Бинарная классификация: детекция матчей при сопоставлении товаров

## Задача

Для решения задачи предоставлены обезличенные данные по товарным предложениям продавцов (offer) и товарам ассортимента маркетплейса "Мегамаркет" (goods). В данных для каждого предложения уже найдены ближайшие товары из ассортимента и указаны основные признаки для этой пары. Необходимо только классифицировать, какая из пар является матчем, а какая — нет.

## Описание данных

**Признаки:**

- offer_depersanalised - идентификаторы предложения
- goods_depersanalised - идентификаторы товара
- sum_length - суммарная длина пары названий и атрибутов в символах
- attrs+title_score - вероятность матча от рескоринговой модели
- offer_price - цена предложения
- item_price - цена товара
- goods_category_id - категория товара
- id - идентификатор пары offer_depersanalised + $ + goods_depersanalised
- target (только в train.csv) - метка класса (0 - не матч, 1 - матч)

**Эмбеддинги:**

- goods_image_vectors и offer_image_vectors - вектора изображений и их идентификаторы для товаров ассортимента и предложений соответственно. 
- goods_title_vectors и offer_title_vectors - вектора названий+атрибутов и их идентификаторы для товаров ассортимента и предложений соответственно.

## Описание проекта

На начальном этапе исследовали сырые данные и выявили ряд проблем:

- Наличие пропусков. Больше всего их в эмбеддингах изображений товаров. Также есть пропуски в цене товаров ассортимента, в id категорий товаров.
- В обучающей выборке наблюдается дисбаланс классов целевого признака.
- Вектора эмбеддингов в массивах не были нормализованы.

При предобработке данных эмбеддинги были нормализованы и объединены с табличными данными. Были удалены дубликаты, а пропуски в массивах были заменены на заглушку - нулевые вектора того же размера. 

Для обучения моделей эмбеддинги не использовались в чистом виде, на их основе была вычислена средняя косинусная схожесть, которая была использованна в качестве одного из признаков. Дополнительно были сгенерированы 2 новых признакак: отношение цены предложения к цене товара из ассортимента и разница в цене. 

В качестве моделей для теста были выбраны:

- LGBMClassifier
- XGBClassifier
- CatBoostClassifier
- Ensemble(xgb+catboost, voting='soft').

Для улучшения метрики пробовали решить проблему дисбаланса классов через гиперпараметры, изменить порог классификации. Для оптимизации гиперпараметров использовалась Optuna.

## Итоги

До дедлайна соревнования в качестве финальной модели был выбран Сatboost, обученный на 5000 деревьев. К предсказаниям применен подобранный порог классификации:

- Public Score составил 0.91962
- Private Score составил 0.9199

После завершения соревнования решение было доработано и в качестве финальной модели был выбран ансамбль (catboost+xgb c подобранными гиперпараметрами), также был применен оптимальный порог классификации:

- Public Score составил 0.92129
- Private Score составил 0.92132

**Полезные решения:**

- использование ансамбля моделей с мягким голосованием;
- генерация новых признаков (отношение и разница цен);
- подбор оптимальных гиперпараметров для моделей, входящих в ансамбль;
- подбор оптимального порога классификации.

**Бесполезные решения:**

- изменение весов классов с дефолтных (вес каждого класса равен 1) на веса классов на основе общего количества объектов в каждом классе.



